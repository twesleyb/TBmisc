# ----Sample loading normalization (scaling)-----------------------------------------------
## Define function: tmt_sl_normalize
#  Sample loading normalization
#  global scaling value, sample loading normalization
#  Modified by TWAB to remove rows in which QC was not quantified in all three replictes, ...
#  ... impute missing values as channel mins, scale raw intensities, and add 1 prior to log.
## Define function: tmt_sl_normalize (NO LOG, no impute)
tmt_sl_normalize <- function(data_in){
# Get info columns
data_info <- data_in[1:(ncol(data_in)-tmt_kit)]
# Get just numerical columns
data_in <- data_in[(ncol(data_in)-tmt_kit+1):ncol(data_in)]
# Replace 0 with NA
data_in[data_in == 0] <- NA
# Get column mins
colmins <- apply(data_in, 2, min, na.rm=TRUE)
# Replace NA with 0
data_in[is.na(data_in)] <- 0
# Remove rows if QC was not quantified in all three runs.
rows_out <-data_in[,1]==0 | data_in[,2]==0 | data_in[,3]==0
nout <- length(rows_out[rows_out==TRUE])
data_in <- data_in[!rows_out,]
data_info <- data_info[!rows_out,]
# SL normalization
target <- mean(colSums(data_in))
norm_facs <- target / colSums(data_in)
data_out_sl <- sweep(data_in, 2, norm_facs, FUN = "*")
data_out_sl <- data_out_sl
data_out_sl <- cbind(data_info, data_out_sl)
return(data_out_sl)
}
# Sample loading normalization (scale to run sums to mean total intensity of runs)
IRS1_sl <- tmt_sl_normalize(IRS1_peptide)
IRS2_sl <- tmt_sl_normalize(IRS2_peptide)
IRS3_sl <- tmt_sl_normalize(IRS3_peptide)
IRS4_sl <- tmt_sl_normalize(IRS4_peptide)
#hist(as.matrix(IRS1_sl[-c(1:5)]))
## Define function: filter_peptides_v2
filter_peptidesv2 <- function(df, sd_factor) {
df$average <- apply(df[(info_count+1):(info_count+4)], 1, FUN = mean)
df$stddev <- apply(df[(info_count+1):(info_count+4)], 1, FUN = sd)
df$cv <- df$stddev / df$average * 100
meanCV = mean(df$cv)
sdCV = sd(df$cv)
Th = sd_factor*sdCV+meanCV
logic = df$cv > Th
length(logic[logic==TRUE])
df2 <- df[!logic,]
df3<- df2[,-c(17:19)]
return(df3)
}
# Filter peptides based on QC CV.[version 2]
sd_factor = 3.0
IRS1_sl_filter <- filter_peptidesv2(IRS1_sl, sd_factor)
IRS2_sl_filter <- filter_peptidesv2(IRS2_sl, sd_factor)
IRS3_sl_filter <- filter_peptidesv2(IRS3_sl, sd_factor)
IRS4_sl_filter <- filter_peptidesv2(IRS4_sl, sd_factor)
# Calculate number of proteins removed...(TWAB)
print(paste(dim(IRS1_sl)[1] - dim(IRS1_sl_filter)[1],"Peptides removed from Syngap1",sep=" "))
print(paste(dim(IRS2_sl)[1] - dim(IRS2_sl_filter)[1], "Peptides removed from Ube3a",sep=" "))
print(paste(dim(IRS3_sl)[1] - dim(IRS3_sl_filter)[1], "Peptides removed from Shank2",sep=" "))
print(paste(dim(IRS4_sl)[1] - dim(IRS4_sl_filter)[1], "Peptides removed from Shank3",sep=" "))
# Get raw data after removing bad peptides...
logic <- IRS1_peptide$`Master Protein Accessions` %in% IRS1_sl_filter$`Master Protein Accessions`
raw.peptide1 <- IRS1_peptide[logic,]
logic <- IRS2_peptide$`Master Protein Accessions` %in% IRS2_sl_filter$`Master Protein Accessions`
raw.peptide2 <- IRS2_peptide[logic,]
logic <- IRS3_peptide$`Master Protein Accessions` %in% IRS3_sl_filter$`Master Protein Accessions`
raw.peptide3 <- IRS3_peptide[logic,]
logic <- IRS4_peptide$`Master Protein Accessions` %in% IRS4_sl_filter$`Master Protein Accessions`
raw.peptide4 <- IRS4_peptide[logic,]
## Define function: filter_peptides_v2
filter_peptidesv2 <- function(df, sd_factor) {
df$average <- apply(df[(info_count+1):(info_count+4)], 1, FUN = mean)
df$stddev <- apply(df[(info_count+1):(info_count+4)], 1, FUN = sd)
df$cv <- df$stddev / df$average * 100
meanCV = mean(df$cv)
sdCV = sd(df$cv)
Th = sd_factor*sdCV+meanCV
logic = df$cv > Th
length(logic[logic==TRUE])
df2 <- df[!logic,]
df3<- df2[,-c(17:19)]
return(df3)
}
# Filter peptides based on QC CV.[version 2]
sd_factor = 3.0
IRS4_sl_filter <- filter_peptidesv2(IRS4_sl, sd_factor)
print(paste(dim(IRS2_sl)[1] - dim(IRS2_sl_filter)[1], "Peptides removed from Ube3a",sep=" "))
print(paste(dim(IRS3_sl)[1] - dim(IRS3_sl_filter)[1], "Peptides removed from Shank2",sep=" "))
raw.peptide1 <- IRS1_peptide[logic,]
# Get raw data after removing bad peptides...
logic <- IRS1_peptide$`Master Protein Accessions` %in% IRS1_sl_filter$`Master Protein Accessions`
# Delete empty rows.
IRS1_peptide <- delete_empty_row(IRS1_peptide)
IRS3_peptide <- delete_empty_row(IRS3_peptide)
head(IRS1_peptide)
View(IRS2_peptide)
## Setting up the workspace:
rm(list = ls())
f = "\f"
library(JGmisc)
## Setting up the workspace:
rm(list = ls())
dev.off()
cat(f) #cat("\014") #alt= > cat("\f")
detachAllPackages(keep = NULL)
## ----Load the data----------------------------------------------------------------------
## Load the data and meta data from excel
library(readxl)
sample_info <- read_excel("4227 TMT Cortex Combined 110718 Sample Info.xlsx", 1)
# Define number of experiments and TMT channels
sets_tmt <- 4
# Define prefixes for data
IRS1_prefix <- "4227_Cortex_Syngap1"
IRS4_prefix <- "4227_Cortex_Shank3"
## ----Clean up the PD data, step 1.------------------------------------------------------
## Define function: protein_to_peptide(data_in)
# Reformats PD data.
protein_to_peptide <- function(data_in){
data_in$`Protein FDR Confidence: Mascot`[is.na(data_in$`Protein FDR Confidence: Mascot`)] <- ""
for(i in 1:nrow(data_in)) {
if(data_in[i,1] == "High") {
set_accession <- data_in[i,3]
set_description <- data_in[i,4]
}else{
data_in[i,3] <- set_accession
data_in[i,4] <- set_description
}
}
peptide_header <- data_in[2,]
data_in <- subset(data_in, Master=="High")
colnames(data_in) <- peptide_header
colnames(data_in)[3] <- "Master Protein Accessions"
colnames(data_in)[4] <- "Description"
data_in <- data_in[,-1]
colnames(data_in)[colnames(data_in) == 'Quan Usage'] <- 'Used'
data_in <- subset(data_in, Used=="Used")
data_in <- data_in[-ncol(data_in)]
data_in <- data_in[-ncol(data_in)]
data_in <- data_in[-ncol(data_in)]
data_in <- data_in[-ncol(data_in)]
data_in[, (ncol(data_in)-43):ncol(data_in)] <- sapply(data_in[, (ncol(data_in)-43):ncol(data_in)], as.numeric)
return(data_in)
}
# Reformat PD protein data... this may take a few minutes.
all_peptide <- protein_to_peptide(all_data)
info_columns <- all_peptide[1:info_count]
## Setting up the workspace:
rm(list = ls())
f = "\f"
cat(f) #cat("\014") #alt= > cat("\f")
install.packages("Rmarkdown")
install.packages("rmarkdown")
1+1
#' ## Setting up the workspace
#+ eval= FALSE
rm(list = ls())
dev.off()
f = "\f"
cat(f) #cat("\014") #alt= > cat("\f")
dev.off()
f = "\f"
cat(f) #cat("\014") #alt= > cat("\f")
# To remove all packages, you can call the following:
library(magrittr)
detachAllPackages(keep = NULL)
#  Load required packages:
suppressPackageStartupMessages({
library(JGmisc)
library(readxl)
library(knitr)
library(kableExtra)
library(dplyr)
library(reshape2)
library("DEP")
library(tibble)
library(SummarizedExperiment)
library(ggplot2)
library(hexbin)
library(vsn)
library(BurStMisc)
library(dplyr)
library(AnnotationDbi)
library(org.Mm.eg.db)
library(edgeR)
library(openxlsx)
library(stringr)
})
# Define tissue type: 1 for cortex, and 2 for striatum
type <- 2
#' Load the data from excel using readxl::read_excel
datafile <- c("4227_TMT_Cortex_Combined_PDoutput.xlsx","4227_TMT_Striatum_Combined_PDoutput.xlsx")
all_data <- read_excel(datafile[type], 1)
sample_info <- read_excel(samplefile[type], 1)
#' Load the data from excel using readxl::read_excel
datafile <- c("4227_TMT_Cortex_Combined_PDoutput.xlsx","4227_TMT_Striatum_Combined_PDoutput.xlsx")
all_data <- read_excel(datafile[type], 1)
library(JGmisc)
detachAllPackages(keep = NULL)
# Load required functions:
source("TMT_Preprocess_Functions.R")
# Define number of experiments and TMT channels
num_exp <- 4
all_data <- read_excel(datafile[type], 1)
# Reformat the peptide data using reshape2::melt
data_work <- melt(raw_peptide) # Warning message is okay!
# Subset each dataset, omit NA, and combine into list:
peptides_syngap1 <- na.omit(data_work[grepl("Syngap1",data_work$variable),])
library(JGmisc)
library(readxl)
library(knitr)
library(kableExtra)
install.packages("readr")
library(dplyr)
library(reshape2)
library(DEP)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("MSnbase", version = "3.8")
library(DEP)
library(tibble)
library(SummarizedExperiment)
library(ggplot2)
library(hexbin)
library(vsn)
library(BurStMisc)
library(dplyr)
library(AnnotationDbi)
library(org.Mm.eg.db)
library(edgeR)
library(limma)
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("limma", version = "3.8")
library(limma)
library(limma)
library(edgeR)
library(openxlsx)
library(stringr)
library(imp4p)
quit
quit()
a + b
a <- 1
b <- 2
a + b
foo <- data.frame(NA,nrow=5,ncol=5)
View(foo)
data.frame(NA,nrow=5,ncol=5)
matrix(nrow=5,ncol=5)
dm <- matrix(nrow=5,ncol=5)
dm
foo <- as.data.frame(dm)
foo
foo$v1
install.packages('tinytex')
tinytex::install_tinytex()
quit()
dev.off()
cat(f) # cat("\014") #alt= > cat("\f")
# Set the working directory
root_dir <- "D:/Documents/R/TMTdataProcessing/Bradshaw"
tissue <- c("Cortex", "Striatum")
# Set paths for saving data and results:
saveresults_path <- paste(root_dir, "/Results/", tissue[type], "/Data", sep = "")
f <- "\f"
cat(f) # cat("\014") #alt= > cat("\f")
# Set the working directory
root_dir <- "D:/Documents/R/TMTdataProcessing/Bradshaw"
# Set path for loading the data and metadat.
input_path <- paste(root_dir, "/Input/", tissue[type], sep = "")
savefigs_path <- paste(root_dir, "/Results/", tissue[type], "/Figures", sep = "")
# Rmarkdown filename.
rm_output <- paste(tissue[type], "_TMT_Analysis", "_", Sys.Date(), ".pdf", sep = "")
# Define tissue type: 1 for cortex, and 2 for striatum
type <- 1
# Set paths for saving data and results:
saveresults_path <- paste(root_dir, "/Results/", tissue[type], "/Data", sep = "")
# Render report.
# Set clean = False to keep temporary files like .Rmd and figures.
script_name <- "TMT_Analysis_v1.R"
rmarkdown::render(script_name, output_file = rm_output, clean = TRUE)
library(JGmisc)
# Load required custom functions.
fun_path <- paste(root_dir, "/Functions/TMT_Preprocess_Functions.R", sep = "")
num_channels <- 11
# Load the data from excel using readxl::read_excel
datafile <- c(
"4227_TMT_Cortex_Combined_PD_Intensity.xlsx",
"4227_TMT_Striatum_Combined_PD_Intensity.xlsx"
)
rm(list = ls())
cat(f) # cat("\014") #alt= > cat("\f")
cat(f)
dev.off()
cat(f) # cat("\014") #alt= > cat("\f")
foo <- c(a,2,b)
foo <- c(1,2,3)
deparse(substitute(foo))
substitute(foo)
deparse(foo)
deparse(substitute(foo))
name <- deparse(substitute(v1))
name <- deparse(substitute(foo))
cat(f)
cat("/f")
cat("\f")
quit()
git
where git
install.packages("swirlify")
library(swirlify)
??swirlify
swirl_courses_dir()
swirl_courses_dir()
quit()
getwd()
create("testpack2")
library(devtools)
library(roxygen2)
devtools::create()
devtools::create("cats")
document()
getwd()
setwd("D:/Users/tyler/Documents/cats")
setwd("D:/Users/tyler/Documents/Cats")
setwd("D:/Users/tyler/Cats")
setwd("D:/Users/tyler/Documents/cats")
setwd("c:/Users/tyler/Documents/cats")
document()
getwd()
install("cats")
getwd()
setwd("C:/Users/tyler/Documents")
install("cats")
getwd()
cd("Cats")
setwd(paste(getwd(),"cats"),sep="/")
setwd(paste(getwd(),"cats",sep="/"))
getwd()
document()
getwd()
setwd("C:/Users/tyler/Documents")
install("cats")
libPaths()
.libPaths()
library(cats)
remove.packages("cats")
file = "test.txt"
class(file)
getwd()
setwd(D:/Documents/R"")
setwd("D:/Documents/R")
getwd()
list.files
list.files()
create("TBmisc")
library(devtools)
create("TBmisc")
getwd()
setwd("D:/Documents/R")
getwd()
setwd("D:/Documents/R/TBmisc")
document()
document()
getwd()
document()
document()
getwd()
install("TBmisc")
setwd("D:\Documents\R")
setwd("D:/Documents/R")
install("TBmisc")
library(TBmisc)
?TBmisc
?TBmisc::touch
getwd()
setwd("D:/Documents/R/TBmisc")
library(devtools)
create("TBmisc")
getwd()
document()
